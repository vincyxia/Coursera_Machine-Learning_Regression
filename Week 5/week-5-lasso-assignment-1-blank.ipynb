{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Graphlab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  after removing the cwd from sys.path.\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 458084894252119.0, tolerance: 291291676192.12994\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
       "      positive=False, precompute=False, random_state=None, selection='cyclic',\n",
       "      tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model_all = linear_model.Lasso(alpha = 0, normalize = True)\n",
    "model_all.fit(sales[all_features],sales['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bedrooms', 'bedrooms_square', 'bathrooms', 'sqft_living',\n",
       "       'sqft_living_sqrt', 'sqft_lot', 'sqft_lot_sqrt', 'floors',\n",
       "       'floors_square', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_1 = model_all.coef_ != 0\n",
    "np_all_features = np.array(all_features)\n",
    "np_all_features[filter_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('wk3_kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure to create the 4 features as we did in #1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty = np.logspace(1,7,num=13)\n",
    "\n",
    "def get_lowest_rss(l1_penalty,training,validation):\n",
    "    for i in range(len(l1_penalty)):\n",
    "        model = linear_model.Lasso(alpha = l1_penalty[i], normalize = True)\n",
    "        model.fit(training.loc[:,all_features], training['price'])\n",
    "        pred_price = model.predict(validation.loc[:,all_features])\n",
    "        error = pred_price - validation['price']\n",
    "        rss = np.dot(error.T,error)\n",
    "        \n",
    "        if i == 0:\n",
    "            lowest_rss = rss\n",
    "            best_l1_penalty = l1_penalty[i]\n",
    "            best_model = model\n",
    "            \n",
    "        if rss < lowest_rss:\n",
    "            lowest_rss = rss\n",
    "            best_l1_penalty = l1_penalty[i]\n",
    "            best_model = model\n",
    "            \n",
    "    return (lowest_rss, best_l1_penalty, best_model)\n",
    "\n",
    "lowest_rss, best_l1_penalty, best_model = get_lowest_rss(l1_penalty, training, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION. *** What was the best value for the `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398213327300134.94\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "print(lowest_rss)\n",
    "print(best_l1_penalty)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(best_model.coef_) + np.count_nonzero(best_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(1, 4, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(1, 4, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 15, 15, 15, 13, 12, 11, 10, 7, 6, 6, 6, 5, 3, 3, 2, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_nonzero(l1_penalty, training):\n",
    "    num_nonzero = []\n",
    "    weights = []\n",
    "    for i in range(len(l1_penalty)):\n",
    "        model = linear_model.Lasso(alpha = l1_penalty[i], normalize = True)\n",
    "        model.fit(training.loc[:,all_features], training['price'])\n",
    "        nonzero = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "        num_nonzero.append(nonzero)\n",
    "    return num_nonzero\n",
    "\n",
    "num_nonzero = get_nonzero(l1_penalty_values, training)\n",
    "num_nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzeros` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzeros` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(num_nonzero.index(6))\n",
    "print(num_nonzero.index(10))\n",
    "l1_penalty_min = l1_penalty_values[num_nonzero.index(6)]\n",
    "l1_penalty_max = l1_penalty_values[num_nonzero.index(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION.*** What values did you find for `l1_penalty_min` and `l1_penalty_max`, respectively? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263.6650898730358\n",
      "127.42749857031335\n"
     ]
    }
   ],
   "source": [
    "print(l1_penalty_min)\n",
    "print(l1_penalty_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(l1_penalty_values, num_nonzero)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_final_l1_penalty(l1_penalty, training, validation, all_features, max_nonzeros):\n",
    "    num_nonzero = []\n",
    "    rss_validation = []\n",
    "    lowest_rss_final = None\n",
    "    lowest_rss_index = None\n",
    "    lowest_rss_model_coefs = None\n",
    "    \n",
    "    for i in range(len(l1_penalty)):\n",
    "        model = linear_model.Lasso(alpha = l1_penalty[i], normalize = True)\n",
    "        model.fit(training.loc[:,all_features],training['price'])\n",
    "        num_nonzero.append(np.count_nonzero(model.coef_)+np.count_nonzero(model.intercept_))\n",
    "        pred_valid = model.predict(validation.loc[:,all_features])\n",
    "        errors = validation['price'] - pred_valid\n",
    "        rss_validation.append(np.dot(errors.T,errors))\n",
    "        \n",
    "        if num_nonzero[i] == max_nonzeros:\n",
    "            if lowest_rss_final is None or rss_validation[i] < lowest_rss_final:\n",
    "                lowest_rss_final = rss_validation[i]\n",
    "                lowest_rss_index = i\n",
    "                lowest_rss_model_coefs = model.coef_\n",
    "    return (lowest_rss_final, l1_penalty[lowest_rss_index], lowest_rss_model_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_rss_final, final_l1_penalty, final_model_coefs = find_final_l1_penalty(l1_penalty_values, training, validation, all_features, max_nonzeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.11\n"
     ]
    }
   ],
   "source": [
    "print(round(final_l1_penalty,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bathrooms', 'sqft_living', 'waterfront', 'view', 'grade',\n",
       "       'yr_built'], dtype='<U16')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_filter = final_model_coefs != 0\n",
    "np_all_features[f_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
